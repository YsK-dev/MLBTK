 # comments sentiment analysis
# %%
! pip install tensorflow
# %%
import numpy as np
import pandas as pd
from gensim.models import Word2Vec

from keras_preprocessing.text import Tokenizer
from keras_preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import SimpleRNN,Embedding, LSTM, Dense, Dropout  

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# %%
# Truncate text list to match label length
data = {
    "text": [
        "Yemekler harikaydÄ±, servis Ã§ok hÄ±zlÄ±ydÄ±.",
        "Garson Ã§ok ilgisizdi, bir daha gelmem.",
        "TatlÄ± mÃ¼kemmeldi ama ana yemek soÄŸuktu.",
        "Mekan Ã§ok gÃ¼rÃ¼ltÃ¼lÃ¼ydÃ¼, keyif alamadÄ±m.",
        "Servis hÄ±zlÄ±ydÄ±, fiyatlar da makuldÃ¼.",
        "Porsiyonlar kÃ¼Ã§Ã¼ktÃ¼, aÃ§ kaldÄ±m.",
        "Her ÅŸey Ã§ok gÃ¼zeldi, kesinlikle tavsiye ederim.",
        "Yemekler yaÄŸlÄ±ydÄ± ama lezzetliydi.",
        "Rezervasyonum olmasÄ±na raÄŸmen 20 dakika bekledim.",
        "GÃ¼ler yÃ¼zlÃ¼ personel, temiz ortam.",
        "Yemeklerin tadÄ± mÃ¼kemmeldi, tekrar geleceÄŸim.",
        "SipariÅŸ Ã§ok geÃ§ geldi, soÄŸumuÅŸtu.",
        "Ambiyans Ã§ok hoÅŸtu, romantik bir akÅŸam geÃ§irdik.",
        "Garsonlar kaba davranÄ±yordu.",
        "Yemek Ã§eÅŸitliliÄŸi Ã§ok iyiydi.",
        "Sandalyeler rahatsÄ±zdÄ±, keyif alamadÄ±m.",
        "Kebap Ã§ok lezzetliydi, sÄ±cak geldi.",
        "Fiyatlar aÅŸÄ±rÄ± pahalÄ±, lezzet de ortalama.",
        "Manzara mÃ¼kemmeldi, yemekler de Ã¶yle.",
        "Et piÅŸmemiÅŸti, midem bozuldu.",
        "TatlÄ±lar taze ve enfesti.",
        "MasamÄ±z geÃ§ hazÄ±rlandÄ±, kÃ¶tÃ¼ baÅŸlangÄ±Ã§.",
        "Lezzetliydi ama beklemeye deÄŸmezdi.",
        "Personel Ã§ok ilgiliydi, Ã§ocuklara oyuncak verdiler.",
        "Hizmet kalitesi Ã§ok dÃ¼ÅŸÃ¼ktÃ¼.",
        "Yemekler hÄ±zlÄ± geldi, sÄ±cak ve tazeydi.",
        "AÃ§Ä±k bÃ¼fe bayattÄ±, hiÃ§ memnun kalmadÄ±m.",
        "KahvaltÄ± tabaÄŸÄ± oldukÃ§a zengindi.",
        "Bir kahveye 80 TL verdik, Ã§ok saÃ§ma.",
        "Rezervasyonumuzu kaydetmemiÅŸler.",
        "Ä°Ã§ dekorasyon Ã§ok ÅŸÄ±ktÄ±.",
        "Garson sipariÅŸleri karÄ±ÅŸtÄ±rdÄ±.",
        "Fiyat performans aÃ§Ä±sÄ±ndan mÃ¼kemmel.",
        "Yemek soÄŸuktu, ilgilenen olmadÄ±.",
        "Tat olarak vasattÄ±, beklentimi karÅŸÄ±lamadÄ±.",
        "Patates kÄ±zartmasÄ± Ã§Ä±tÄ±r Ã§Ä±tÄ±rdÄ±.",
        "MÃ¼ÅŸteri memnuniyeti sÄ±fÄ±r.",
        "Yemekler Ã§ok geÃ§ geldi, Ã¼stelik soÄŸuktu.",
        "Makarna sosu Ã§ok gÃ¼zeldi.",
        "Ä°lgili Ã§alÄ±ÅŸanlar ve temiz bir mekan.",
        "TatlÄ±larÄ±n sunumu muhteÅŸemdi.",
        "SipariÅŸ verdiÄŸim yemek baÅŸka bir ÅŸeydi.",
        "BahÅŸiÅŸ istemeleri hoÅŸuma gitmedi.",
        "Aile ortamÄ± Ã§ok hoÅŸtu.",
        "Ã‡orba sanki dÃ¼nden kalmaydÄ±.",
        "HÄ±zlÄ± servis ve gÃ¼zel sunum.",
        "Mekanda sigara iÃ§iliyordu, rahatsÄ±z oldum.",
        "Kahve yanÄ±nda lokum getirmeleri hoÅŸ detaydÄ±.",
        "AÅŸÃ§Ä±nÄ±n Ã¶zel yemeÄŸi Ã§ok lezzetliydi.",
        "Ä°lk ve son geliÅŸim.",
        "Servis personeli Ã§ok saygÄ±lÄ±ydÄ±.",
        "Yemekler doyurucu ve kaliteliydi.",
        "Ä°ndirim olmasÄ±na raÄŸmen kaliteden Ã¶dÃ¼n verilmemiÅŸti.",
        "Ä°Ã§ecekler eksik geldi.",
        "Kebaplar tam kÄ±vamÄ±ndaydÄ±.",
        "Ã‡ok gÃ¼rÃ¼ltÃ¼lÃ¼, dinlenemedik.",
        "Manzaraya karÅŸÄ± Ã§ay iÃ§mek harikaydÄ±.",
        "Ã‡alÄ±ÅŸanlar oldukÃ§a ilgisizdi.",
        "TatlÄ±dan sinek Ã§Ä±ktÄ±.",
        "Restoran Ã§ok temizdi.",
        "Yemek sipariÅŸi karÄ±ÅŸtÄ± ama telafi ettiler.",
        "Fiyatlar Ã§ok uygun.",
        "Sadece manzara iÃ§in gidilir.",
        "MÃ¼ÅŸteriyle ilgilenmiyorlar.",
        "TatlÄ± menÃ¼sÃ¼ Ã§ok baÅŸarÄ±lÄ±ydÄ±.",
        "SÄ±nÄ±rlÄ± menÃ¼, alternatif yoktu.",
        "Ä°kramlar Ã§ok cÃ¶mertti.",
        "KÃ¶tÃ¼ servis, lezzetsiz yemekler.",
        "Sunum harikaydÄ±, tadÄ± da Ã¶yle.",
        "Masalar Ã§ok sÄ±kÄ±ÅŸÄ±k yerleÅŸtirilmiÅŸti.",
        "Yemekten sonra ikram edilen Ã§ay Ã§ok gÃ¼zeldi.",
        "AÅŸÄ±rÄ± yaÄŸlÄ±ydÄ±, mide bulandÄ±rÄ±cÄ±.",
        "Ã‡ocuklar iÃ§in oyun alanÄ± olmasÄ± bÃ¼yÃ¼k avantaj.",
        "Sadece tatlÄ±lar gÃ¼zeldi, gerisi vasat.",
        "Ã‡alÄ±ÅŸanlar Ã§ok cana yakÄ±ndÄ±.",
        "TabaÄŸÄ±mda saÃ§ Ã§Ä±ktÄ±!",
        "Ambiyans harikaydÄ±.",
        "Ã‡ok bekledik ama deÄŸdi.",
        "Bekleme sÃ¼resi aÅŸÄ±rÄ± uzundu.",
        "Her ÅŸey taze ve lezzetliydi.",
        "Servis yavaÅŸtÄ± ama yemekler telafi etti.",
        "GÃ¶zleme Ã§ok lezzetliydi.",
        "Garsonlar saygÄ±lÄ±ydÄ± ama yemekler kÃ¶tÃ¼ydÃ¼.",
        "Ä°lk defa gittim, Ã§ok memnun kaldÄ±m.",
        "Buz gibi yemek geldi.",
        "Lezzet ÅŸahane ama porsiyon kÃ¼Ã§Ã¼k.",
        "Yemek sonrasÄ± ikram hoÅŸ bir sÃ¼rprizdi.",
        "Etin iÃ§i Ã§iÄŸdi.",
        "GÃ¼leryÃ¼zlÃ¼ hizmet ve nefis tatlar.",
        "Ä°Ã§ecekler Ã§ok pahalÄ±ydÄ±.",
        "DÃ¼ÄŸÃ¼nÃ¼mÃ¼zÃ¼ burada yaptÄ±k, her ÅŸey mÃ¼kemmeldi.",
        "SoÄŸuk Ã§ay verdiler.",
        "Tavuk Ã§ok gÃ¼zel piÅŸmiÅŸti.",
        "SipariÅŸ yanlÄ±ÅŸ geldi, dÃ¼zeltmediler.",
        "KahvaltÄ±sÄ± Ã§ok zayÄ±ftÄ±.",
        "Personel Ã§ocuklarla Ã§ok ilgilendi.",
        "KalabalÄ±k ama organizasyon iyiydi.",
        "Koku Ã§ok kÃ¶tÃ¼ydÃ¼.",
        "HÄ±zlÄ± ve sÄ±cak servis.",
        "GÃ¼zel manzara, kÃ¶tÃ¼ yemek.",
        "TatlÄ±nÄ±n yanÄ±nda kahve ikramÄ± Ã§ok hoÅŸtu.",
        "Bir daha gelmem, memnun kalmadÄ±m.",
        "Deniz Ã¼rÃ¼nleri Ã§ok tazeydi.",
        "Garsonlar masamÄ±zÄ± sÃ¼rekli unuttu.",
        "PizzasÄ± mÃ¼kemmeldi.",
        "SipariÅŸimiz eksik geldi ama hemen hallettiler.",
        "Ä°Ã§ecekler buz gibiydi, Ã§ok serinleticiydi.",
        "Kuru ve tatsÄ±zdÄ±, beÄŸenmedim."
    ][:100],  # ğŸ‘ˆ This trims it to 100 exactly
    "label": [
        "positive", "negative", "neutral", "negative", "positive", "negative", "positive", "neutral", "negative", "positive",
        "positive", "negative", "positive", "negative", "positive", "negative", "positive", "negative", "positive", "negative",
        "positive", "negative", "neutral", "positive", "negative", "positive", "negative", "positive", "negative", "negative",
        "positive", "negative", "negative", "positive", "negative", "negative", "negative", "positive", "positive", "positive",
        "negative", "negative", "positive", "negative", "positive", "negative", "positive", "positive", "negative", "positive",
        "positive", "positive", "negative", "positive", "negative", "positive", "negative", "negative", "positive", "neutral",
        "negative", "positive", "negative", "positive", "negative", "positive", "negative", "positive", "positive", "positive",
        "negative", "positive", "neutral", "positive", "negative", "positive", "negative", "positive", "negative", "positive",
        "negative", "positive", "negative", "positive", "negative", "positive", "negative", "positive", "negative", "positive",
        "negative", "positive", "negative", "positive", "negative", "positive", "positive", "negative", "positive", "negative"
    ]
}

# âœ… Check that both lengths match
print(f"Number of texts: {len(data['text'])}")
print(f"Number of labels: {len(data['label'])}")

#%%
# tokenize the text
tokenizer = Tokenizer()
tokenizer.fit_on_texts(data['text'])
sequences = tokenizer.texts_to_sequences(data['text'])
word_index = tokenizer.word_index
print(f"Found {len(word_index)} unique tokens.")
# %%
# pad the sequences
max_length = max(len(seq) for seq in sequences)
padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')
print(padded_sequences.shape)

# %%
Label_encoder = LabelEncoder()
labels = Label_encoder.fit_transform(data['label'])
print(f"Encoded labels: {labels}")
# %%
# split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)
print(f"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}")
# %%

sentences = [text.split() for text in data['text']]
# train a Word2Vec model
word2vec_model = Word2Vec(sentences, vector_size=50, window=5 , min_count=1, workers=4)

# create an embedding matrix
emmeding_matrix = np.zeros((len(word_index) + 1, 50))
for word, i in word_index.items():
    emmeding_vector = word2vec_model.wv[word] if word in word2vec_model.wv else None
    if emmeding_vector is not None:
        emmeding_matrix[i] = emmeding_vector

# %%
model = Sequential()
model.add(Embedding(input_dim=len(word_index) + 1, output_dim=50,
                  weights=[emmeding_matrix], input_length=max_length, trainable=False))
model.add(SimpleRNN(64, return_sequences=True))
model.add(Dropout(0.5))
model.add(SimpleRNN(32))
model.add(Dropout(0.5))
model.add(Dense(3, activation='sigmoid'))  # 3 classes: positive, negative, neutral
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=10, batch_size=3, validation_data=(X_test, y_test), verbose=1) 

# %%
model.summary()
# %%
# evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")

# %%
# make predictions
def predict_sentiment(text):
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')
    prediction = model.predict(padded_sequence)
    predicted_label = np.argmax(prediction, axis=1)
    return Label_encoder.inverse_transform(predicted_label)[0]

# Test the prediction function
test_texts = [
    "Yemekler Ã§ok lezzetliydi, tekrar geleceÄŸim.",
    "Garson Ã§ok ilgisizdi, bir daha gelmem.",
    "TatlÄ± mÃ¼kemmeldi ama ana yemek soÄŸuktu."]
for text in test_texts:
    sentiment = predict_sentiment(text)
    print(f"Text: {text}\nPredicted Sentiment: {sentiment}\n")
# %%
